{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# You cannot change this lines.\n",
    "from tools.dataloader import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x) + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, ResidualBlock):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Reference: https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "# The original model is a ResNet model. I modified its parameters and changed it to a ResNet-18 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameter optimization in assignment 4(a), 4(b) can be \n",
    "conducted here.\n",
    "Be sure to leave only your best hyperparameter combination\n",
    "here and comment the original hyperparameter settings.\n",
    "\"\"\"\n",
    "\n",
    "# Setting some hyperparameters\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 50\n",
    "INITIAL_LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "REG = 5e-4\n",
    "EPOCHS = 30\n",
    "DATAROOT = \"./data\"\n",
    "CHECKPOINT_PATH = \"./saved_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\cifar10_trainval.tar.gz\n",
      "Extracting ./data\\cifar10_trainval.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root=DATAROOT, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                                          num_workers=1)\n",
    "valset = CIFAR10(root=DATAROOT, train=False, download=False, transform=transform_val)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=False, \n",
    "                                        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU...\n"
     ]
    }
   ],
   "source": [
    "# Specify the device for computation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = ResNet18(ResidualBlock)\n",
    "net = net.to(device)\n",
    "if device =='cuda':\n",
    "    print(\"Train on GPU...\")\n",
    "else:\n",
    "    print(\"Train on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded checkpoint: ./saved_model/model.h5\n",
      "Starting from epoch 24 \n",
      "Starting from learning rate 0.001000:\n"
     ]
    }
   ],
   "source": [
    "# FLAG for loading the pretrained model\n",
    "TRAIN_FROM_SCRATCH = False\n",
    "# Code for loading checkpoint and recover epoch id.\n",
    "CKPT_PATH = \"./saved_model/model.h5\"\n",
    "def get_checkpoint(ckpt_path):\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return ckpt\n",
    "\n",
    "ckpt = get_checkpoint(CKPT_PATH)\n",
    "if ckpt is None or TRAIN_FROM_SCRATCH:\n",
    "    if not TRAIN_FROM_SCRATCH:\n",
    "        print(\"Checkpoint not found.\")\n",
    "    print(\"Training from scratch ...\")\n",
    "    start_epoch = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "else:\n",
    "    print(\"Successfully loaded checkpoint: %s\" %CKPT_PATH)\n",
    "    net.load_state_dict(ckpt['net'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    current_learning_rate = ckpt['lr']\n",
    "    print(\"Starting from epoch %d \" %start_epoch)\n",
    "\n",
    "print(\"Starting from learning rate %f:\" %current_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 2(c)\n",
    "In the targeted classification task, we use cross entropy loss with L2 \n",
    "regularization as the learning object.\n",
    "You need to formulate the cross-entropy loss function in PyTorch.\n",
    "You should also specify a PyTorch Optimizer to optimize this loss function.\n",
    "We recommend you to use the SGD-momentum with an initial learning rate 0.01 \n",
    "and momentum 0.9 as a start.\n",
    "\"\"\"\n",
    "# Create loss function and specify regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Add optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr=INITIAL_LR,momentum=MOMENTUM,weight_decay=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01 17:42:04.305836\n",
      "Epoch 4:\n",
      "352\n",
      "Training loss: 0.5239, Training accuracy: 0.8169\n",
      "2019-10-01 17:43:35.089755\n",
      "Testing...\n",
      "Testing loss: 0.6735, Testing accuracy: 0.7658\n",
      "Saving ...\n",
      "2019-10-01 17:43:39.437652\n",
      "Epoch 5:\n",
      "352\n",
      "Training loss: 0.4810, Training accuracy: 0.8326\n",
      "2019-10-01 17:45:13.637821\n",
      "Testing...\n",
      "Testing loss: 0.6610, Testing accuracy: 0.7704\n",
      "Saving ...\n",
      "2019-10-01 17:45:18.067819\n",
      "Epoch 6:\n",
      "352\n",
      "Training loss: 0.4440, Training accuracy: 0.8461\n",
      "2019-10-01 17:46:53.181261\n",
      "Testing...\n",
      "Testing loss: 0.5628, Testing accuracy: 0.8000\n",
      "Saving ...\n",
      "2019-10-01 17:46:57.549379\n",
      "Epoch 7:\n",
      "352\n",
      "Training loss: 0.4157, Training accuracy: 0.8556\n",
      "2019-10-01 17:48:32.772515\n",
      "Testing...\n",
      "Testing loss: 0.6025, Testing accuracy: 0.7980\n",
      "2019-10-01 17:48:37.067541\n",
      "Epoch 8:\n",
      "352\n",
      "Training loss: 0.3844, Training accuracy: 0.8658\n",
      "2019-10-01 17:50:12.503019\n",
      "Testing...\n",
      "Testing loss: 0.6529, Testing accuracy: 0.7832\n",
      "2019-10-01 17:50:16.791996\n",
      "Epoch 9:\n",
      "352\n",
      "Training loss: 0.3691, Training accuracy: 0.8722\n",
      "2019-10-01 17:51:52.439291\n",
      "Testing...\n",
      "Testing loss: 0.5939, Testing accuracy: 0.8008\n",
      "Saving ...\n",
      "2019-10-01 17:51:56.790142\n",
      "Epoch 10:\n",
      "352\n",
      "Training loss: 0.3433, Training accuracy: 0.8800\n",
      "2019-10-01 17:53:32.414773\n",
      "Testing...\n",
      "Testing loss: 0.7413, Testing accuracy: 0.7594\n",
      "Current learning rate has decayed to 0.010000\n",
      "2019-10-01 17:53:36.760936\n",
      "Epoch 11:\n",
      "352\n",
      "Training loss: 0.1854, Training accuracy: 0.9408\n",
      "2019-10-01 17:55:12.531767\n",
      "Testing...\n",
      "Testing loss: 0.3687, Testing accuracy: 0.8776\n",
      "Saving ...\n",
      "2019-10-01 17:55:16.944018\n",
      "Epoch 12:\n",
      "352\n",
      "Training loss: 0.1180, Training accuracy: 0.9649\n",
      "2019-10-01 17:56:52.599942\n",
      "Testing...\n",
      "Testing loss: 0.3615, Testing accuracy: 0.8834\n",
      "Saving ...\n",
      "2019-10-01 17:56:57.004975\n",
      "Epoch 13:\n",
      "352\n",
      "Training loss: 0.0832, Training accuracy: 0.9752\n",
      "2019-10-01 17:58:32.652192\n",
      "Testing...\n",
      "Testing loss: 0.3753, Testing accuracy: 0.8830\n",
      "2019-10-01 17:58:36.982064\n",
      "Epoch 14:\n",
      "352\n",
      "Training loss: 0.0587, Training accuracy: 0.9844\n",
      "2019-10-01 18:00:12.693174\n",
      "Testing...\n",
      "Testing loss: 0.3879, Testing accuracy: 0.8824\n",
      "2019-10-01 18:00:16.966181\n",
      "Epoch 15:\n",
      "352\n",
      "Training loss: 0.0422, Training accuracy: 0.9902\n",
      "2019-10-01 18:01:52.680271\n",
      "Testing...\n",
      "Testing loss: 0.3904, Testing accuracy: 0.8826\n",
      "2019-10-01 18:01:57.055795\n",
      "Epoch 16:\n",
      "352\n",
      "Training loss: 0.0298, Training accuracy: 0.9937\n",
      "2019-10-01 18:03:56.921268\n",
      "Testing...\n",
      "Testing loss: 0.4038, Testing accuracy: 0.8854\n",
      "Saving ...\n",
      "2019-10-01 18:04:01.172103\n",
      "Epoch 17:\n",
      "352\n",
      "Training loss: 0.0219, Training accuracy: 0.9961\n",
      "2019-10-01 18:05:35.343531\n",
      "Testing...\n",
      "Testing loss: 0.4147, Testing accuracy: 0.8860\n",
      "Saving ...\n",
      "2019-10-01 18:05:39.603540\n",
      "Epoch 18:\n",
      "352\n",
      "Training loss: 0.0145, Training accuracy: 0.9978\n",
      "2019-10-01 18:07:13.735525\n",
      "Testing...\n",
      "Testing loss: 0.4105, Testing accuracy: 0.8858\n",
      "2019-10-01 18:07:18.109792\n",
      "Epoch 19:\n",
      "352\n",
      "Training loss: 0.0113, Training accuracy: 0.9988\n",
      "2019-10-01 18:08:52.149456\n",
      "Testing...\n",
      "Testing loss: 0.4253, Testing accuracy: 0.8856\n",
      "2019-10-01 18:08:56.422165\n",
      "Epoch 20:\n",
      "352\n",
      "Training loss: 0.0086, Training accuracy: 0.9993\n",
      "2019-10-01 18:10:30.908597\n",
      "Testing...\n",
      "Testing loss: 0.4306, Testing accuracy: 0.8846\n",
      "Current learning rate has decayed to 0.001000\n",
      "2019-10-01 18:10:35.290804\n",
      "Epoch 21:\n",
      "352\n",
      "Training loss: 0.0068, Training accuracy: 0.9997\n",
      "2019-10-01 18:12:09.286593\n",
      "Testing...\n",
      "Testing loss: 0.4242, Testing accuracy: 0.8844\n",
      "2019-10-01 18:12:13.518033\n",
      "Epoch 22:\n",
      "352\n",
      "Training loss: 0.0064, Training accuracy: 0.9998\n",
      "2019-10-01 18:13:47.236903\n",
      "Testing...\n",
      "Testing loss: 0.4244, Testing accuracy: 0.8860\n",
      "2019-10-01 18:13:51.454607\n",
      "Epoch 23:\n",
      "352\n",
      "Training loss: 0.0059, Training accuracy: 0.9998\n",
      "2019-10-01 18:15:25.626561\n",
      "Testing...\n",
      "Testing loss: 0.4214, Testing accuracy: 0.8880\n",
      "Saving ...\n",
      "2019-10-01 18:15:29.955365\n",
      "Epoch 24:\n",
      "352\n",
      "Training loss: 0.0055, Training accuracy: 0.9998\n",
      "2019-10-01 18:17:04.018652\n",
      "Testing...\n",
      "Testing loss: 0.4284, Testing accuracy: 0.8874\n",
      "2019-10-01 18:17:08.362287\n",
      "Epoch 25:\n",
      "352\n",
      "Training loss: 0.0054, Training accuracy: 0.9999\n",
      "2019-10-01 18:18:42.381047\n",
      "Testing...\n",
      "Testing loss: 0.4245, Testing accuracy: 0.8866\n",
      "2019-10-01 18:18:46.597872\n",
      "Epoch 26:\n",
      "352\n",
      "Training loss: 0.0053, Training accuracy: 0.9999\n",
      "2019-10-01 18:20:20.628431\n",
      "Testing...\n",
      "Testing loss: 0.4249, Testing accuracy: 0.8870\n",
      "2019-10-01 18:20:24.853951\n",
      "Epoch 27:\n",
      "352\n",
      "Training loss: 0.0052, Training accuracy: 0.9999\n",
      "2019-10-01 18:21:59.163907\n",
      "Testing...\n",
      "Testing loss: 0.4271, Testing accuracy: 0.8874\n",
      "2019-10-01 18:22:03.489028\n",
      "Epoch 28:\n",
      "352\n",
      "Training loss: 0.0051, Training accuracy: 0.9999\n",
      "2019-10-01 18:23:37.458289\n",
      "Testing...\n",
      "Testing loss: 0.4257, Testing accuracy: 0.8860\n",
      "2019-10-01 18:23:41.985609\n",
      "Epoch 29:\n",
      "352\n",
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "2019-10-01 18:25:15.929206\n",
      "Testing...\n",
      "Testing loss: 0.4272, Testing accuracy: 0.8866\n",
      "Optimization finished.\n"
     ]
    }
   ],
   "source": [
    "# Implement Augmentation and batch normalization\n",
    "global_step = 0\n",
    "best_test_acc = 0\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for i in range(start_epoch, EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    # Switch to train mode\n",
    "    net.train()\n",
    "    print(\"Epoch %d:\" %i)\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    # Train the training dataset for 1 epoch.\n",
    "    print(len(trainloader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # Copy inputs to device\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Generate output\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Now backward loss\n",
    "        loss.backward()\n",
    "        # Apply gradient\n",
    "        optimizer.step()\n",
    "        # Calculate predicted labels\n",
    "        _, predicted = outputs.max(1)\n",
    "        # Calculate accuracy\n",
    "        total_examples += len(targets)\n",
    "        correct_examples += np.sum((predicted.cpu() - targets.cpu()).numpy() == 0)\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 100 == 0:\n",
    "            avg_loss = train_loss / (batch_idx + 1)\n",
    "        pass\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    train_acc_list.append(avg_acc)\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "    print(datetime.datetime.now())\n",
    "    # Validate on the validation dataset\n",
    "    print(\"Testing...\")\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    # Disable gradient during validation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            # Copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs,targets)\n",
    "            # Calculate predicted labels\n",
    "            _, predicted = outputs.max(1)\n",
    "            if batch_idx == 0:\n",
    "                final_pred = predicted.cpu().numpy()\n",
    "            else:\n",
    "                final_pred = np.append(final_pred,predicted.cpu().numpy())\n",
    "            # Calculate accuracy\n",
    "            total_examples += len(targets)\n",
    "            correct_examples +=  np.sum((predicted.cpu() - targets.cpu()).numpy() == 0)\n",
    "            test_loss += loss\n",
    "\n",
    "    avg_loss = test_loss / len(valloader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    test_acc_list.append(avg_acc)\n",
    "    print(\"Testing loss: %.4f, Testing accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "    \n",
    "    \"\"\"\n",
    "    Assignment 4(b)\n",
    "    Learning rate is an important hyperparameter to tune. Specify a \n",
    "    learning rate decay policy and apply it in your training process. \n",
    "    Briefly describe its impact on the learning curveduring your \n",
    "    training process.    \n",
    "    Reference learning rate schedule: \n",
    "    decay 0.98 for every 2 epochs. You may tune this parameter but \n",
    "    minimal gain will be achieved.\n",
    "    Assignment 4(c)\n",
    "    As we can see from above, hyperparameter optimization is critical \n",
    "    to obtain a good performance of DNN models. Try to fine-tune the \n",
    "    model to over 70% accuracy. You may also increase the number of \n",
    "    epochs to up to 100 during the process. Briefly describe what you \n",
    "    have tried to improve the performance of the LeNet-5 model.\n",
    "    \"\"\"\n",
    "    DECAY_EPOCHS = 10\n",
    "    DECAY = 0.1\n",
    "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
    "        if i == 0:\n",
    "            current_learning_rate = INITIAL_LR\n",
    "        else:\n",
    "            current_learning_rate *= DECAY\n",
    "        for param_group in optimizer.param_groups:\n",
    "            # Assign the learning rate parameter\n",
    "            param_group['lr'] = current_learning_rate\n",
    "            print(\"Current learning rate has decayed to %f\"%current_learning_rate)\n",
    "    \n",
    "    # Save for checkpoint\n",
    "    if avg_acc > best_test_acc:\n",
    "        best_test_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.makedirs(CHECKPOINT_PATH)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'net': net.state_dict(),\n",
    "                 'epoch': i,\n",
    "                 'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_PATH, 'model.h5'))\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(EPOCHS-start_epoch),train_acc_list,label='train')\n",
    "plt.plot(range(EPOCHS-start_epoch),test_acc_list,label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = CIFAR10(root=DATAROOT, train=False, download=False, transform=transform_val)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=False, \n",
    "                                        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "        # Copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Generate output from the DNN.\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Calculate predicted labels\n",
    "        _, predicted = outputs.max(1)\n",
    "        if batch_idx == 0:\n",
    "            final_pred = predicted.cpu().numpy()\n",
    "        else:\n",
    "            final_pred = np.append(final_pred,predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.read_csv('sample_labels.csv')\n",
    "pred_df['Category'] = final_pred\n",
    "pred_df.to_csv('test.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "    \n",
    "class Testset(torch.utils.data.Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = np.load('./data/cifar10-batches-images-test.npy')\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = self.data[index]\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Testset(transform = transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Testset at 0x251107ff160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-54f6c311347f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, inputs in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        if batch_idx == 0:\n",
    "            final_pred = predicted.cpu().numpy()\n",
    "        else:\n",
    "            final_pred = np.append(final_pred,predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccx = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "5 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0961070dc487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mccx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 5 is not in list"
     ]
    }
   ],
   "source": [
    "ccx.index(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(2, 5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
